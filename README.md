# Full-Stack Excel Analysis Application

This application allows users to upload large Excel files (~25,000 rows of time-series partner/affiliate data), analyze them using `unstructured`, Pandas, and LangChain, and display KPIs and insights with rich visualizations.

## Project Structure

```
project-root/
├── backend/                  # Flask backend
│   ├── app.py                # Main Flask application
│   ├── analysis/             # Data analysis modules
│   │   ├── kpi_calculator.py
│   │   ├── performance_analyzer.py
│   │   ├── rag_engine.py
│   │   └── __init__.py
│   ├── utils/                # Utility functions
│   │   ├── file_parser.py
│   │   └── dotenv_loader.py
│   ├── uploads/              # Temporary storage for uploaded files (auto-created)
│   ├── requirements.txt      # Python dependencies
│   └── .env                  # Environment variables (create manually)
│
├── frontend/                 # React frontend
│   ├── public/
│   ├── src/
│   │   ├── components/       # Reusable React components (add as needed)
│   │   ├── pages/            # Page components (DashboardPage, UploadPage)
│   │   ├── services/         # API service (api.js)
│   │   ├── App.js            # Main React app component
│   │   ├── App.css           # Global styles
│   │   └── index.js          # React entry point (usually auto-generated by CRA/Vite)
│   ├── package.json          # NPM dependencies and scripts
│   └── .env                  # Frontend environment variables (create manually)
│
└── README.md
```

## Prerequisites

*   Python 3.10+ (User mentioned 3.12, which is fine)
*   Node.js and npm (or yarn)
*   Access to an OpenAI API key (or a compatible API for LangChain)

## Setup

### 1. Backend Setup

Navigate to the `backend` directory:
```bash
cd backend
```

Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

Install Python dependencies:
```bash
pip install -r requirements.txt
```

Create a `.env` file in the `backend` directory (`backend/.env`) and add your environment variables. **Important**: The `OPENAI_API_KEY` is crucial for LangChain functionality.

```env
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL_NAME=gpt-3.5-turbo # Or your preferred model, e.g., gpt-4.1-mini
# API_BASE_URL=https://litellm.deriv.ai/v1 # Uncomment and use if you are using a proxy like LiteLLM
# SEARCH_MODEL_NAME=sonar-pro # If needed for specific LangChain setups
```

### 2. Frontend Setup

Navigate to the `frontend` directory:
```bash
cd frontend
```

Install NPM packages:
```bash
npm install
# or if you use yarn: yarn install
```

Create a `.env` file in the `frontend` directory (`frontend/.env`) for the React app:
```env
REACT_APP_API_BASE_URL=http://127.0.0.1:5000
```
This tells the React app where the Flask backend is running.

## Running the Application

1.  **Start the Backend (Flask) Server:**

    Open a terminal, navigate to the `backend` directory, activate your virtual environment (if you created one), and run:
    ```bash
    flask run
    # Or directly: python app.py
    ```
    The backend should start on `http://127.0.0.1:5000` by default.

2.  **Start the Frontend (React) Development Server:**

    Open another terminal, navigate to the `frontend` directory, and run:
    ```bash
    npm start
    # or if you use yarn: yarn start
    ```
    The React development server should start, and it will likely open the application in your web browser (usually `http://localhost:3000`).

## Usage

1.  Open the application in your browser (e.g., `http://localhost:3000`).
2.  You should see the "Upload" page.
3.  Click the "Choose File" button, select an Excel file (.xlsx) with your partner data.
4.  Click "Upload and Analyze".
5.  If successful, you will be redirected to the "Dashboard" page, where KPIs and data insights will be displayed.
6.  On the Dashboard, you can try using the RAG query box to ask questions about your data.

## Key Features & Libraries

*   **Frontend:** React, Chart.js (or Plotly/D3.js can be integrated), Axios
*   **Backend:** Flask, Pandas
*   **Excel Parsing:** `unstructured` library (`partition_xlsx`)
*   **NLP/RAG:** LangChain (with OpenAI or compatible models)
*   **Environment Management:** `python-dotenv` (backend), CRA-style `.env` (frontend)

## Notes on Data Columns

The backend analysis scripts (`kpi_calculator.py`, `performance_analyzer.py`) make assumptions about the column names in your Excel file. You will likely need to adjust these in the Python scripts if your column names differ. Key assumed columns include:

*   `Date` (for time-series analysis, convertible to datetime)
*   `Expected Revenue`
*   `Deriv Revenue`
*   `Partner Commissions`
*   `Total Deposits`
*   `Active Clients`
*   `FTT` (First-Time Traders)
*   `Partner ID`
*   `Region`
*   `Country`

Ensure your Excel file is structured with these (or similar) headers, or modify the Python scripts accordingly.

## Further Development & Charting

*   **Charting:** The `DashboardPage.js` currently has placeholders for charts. You'll need to integrate `react-chartjs-2`, `react-plotly.js`, or D3.js to render visualizations based on the data received from the backend.
    *   Uncomment the Chart.js registration in `DashboardPage.js` if you proceed with Chart.js.
    *   Adapt the data structures from the backend to fit the format required by your chosen charting library.
*   **RAG State Management:** The `/query-rag` backend endpoint and its usage in `DashboardPage.js` are currently very basic. For a robust RAG feature, the backend needs to manage the state of the loaded data/RAG engine (e.g., per session or by referencing a processed file ID) so that queries are directed to the correct dataset.
*   **Error Handling & UX:** Enhance error handling and user feedback on both frontend and backend.
*   **Styling:** The UI is basic. Improve styling for a modern, clean look.
*   **Advanced Analysis:** Implement more sophisticated analyses like partner retention, churn detection, and at-risk identification in `performance_analyzer.py`. 